{ 
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# UserBased Class: Same as Hüsnü Hoca's\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import trange\n",
        "\n",
        "\n",
        "class UserBased:\n",
        "    mu: np.ndarray\n",
        "    sim: np.ndarray\n",
        "\n",
        "    def __init__(self, zero_mean: bool = True, beta: int = 1, idf: bool = False, verbosity: int = 0):\n",
        "        \"\"\"\n",
        "        :param zero_mean:\n",
        "        :param beta: Discounting parameter\n",
        "        :param idf: Enable inverse document frequency management\n",
        "        \"\"\"\n",
        "        self.zero_mean = zero_mean\n",
        "        self.beta = beta\n",
        "        self.idf = idf\n",
        "        self.verbosity = verbosity\n",
        "\n",
        "    def fit(self, r: np.ndarray):\n",
        "        m, n = r.shape\n",
        "        if self.zero_mean:\n",
        "            self.mu = np.nanmean(r, axis=1)\n",
        "        else:\n",
        "            self.mu = np.zeros(m)\n",
        "\n",
        "        self.sim = np.zeros((m, m))\n",
        "\n",
        "        if self.idf:\n",
        "            idf = np.log(1 + m / (~np.isnan(r)).sum(axis=0))\n",
        "        else:\n",
        "            idf = np.ones(n)\n",
        "\n",
        "        if self.verbosity > 0:\n",
        "            print(idf)\n",
        "\n",
        "        for i in trange(m):\n",
        "            for j in range(m):\n",
        "                mask = ~np.isnan(r[i, :]) & ~np.isnan(r[j, :])\n",
        "\n",
        "                si = r[i, mask] - self.mu[i]\n",
        "                sj = r[j, mask] - self.mu[j]\n",
        "\n",
        "                self.sim[i][j] = (si * sj * idf[mask]).sum() / (\n",
        "                        np.sqrt((idf[mask] * (si ** 2)).sum()) * np.sqrt((idf[mask] * (sj ** 2)).sum()))\n",
        "\n",
        "                total_intersection = mask.sum()\n",
        "\n",
        "                self.sim[i][j] *= min(total_intersection, self.beta) / self.beta\n",
        "\n",
        "        return self.sim\n",
        "\n",
        "    def predict(self, r: np.array, u: int, top_k: int = 3) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        :param r: Rating matrix\n",
        "        :param u: User u\n",
        "        :param top_k: Top k neighbourhood\n",
        "        :return: Calculated Rating of each item\n",
        "        \"\"\"\n",
        "\n",
        "        _, n = r.shape\n",
        "\n",
        "        score = np.zeros(n)\n",
        "\n",
        "        for j in trange(n):\n",
        "            score[j] = self.predict1(r, u, j, top_k)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def predict1(self, r: np.array, u: int, j: int, top_k: int = 3) -> float:\n",
        "        _, n = r.shape\n",
        "\n",
        "        users_rated_j = np.nonzero(~np.isnan(r[:, j]))[0]\n",
        "\n",
        "        topk_users = users_rated_j[self.sim[u, users_rated_j].argsort()[::-1][:top_k]]\n",
        "\n",
        "        mean_centered_topk_user_rate = r[topk_users, j] - self.mu[topk_users]\n",
        "\n",
        "        w = self.sim[u, topk_users]\n",
        "\n",
        "        return np.dot(mean_centered_topk_user_rate, w) / np.abs(w).sum() + self.mu[u]"
      ],
      "metadata": {
        "id": "7TMnZqck5uTZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Code: Same as Hüsnü Hoca's\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rich.console import Console\n",
        "\n",
        "cons = Console()\n",
        "\n",
        "df = pd.read_csv('https://files.grouplens.org/datasets/movielens/ml-100k/u.data', delimiter=r'\\t',\n",
        "                 names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
        "\n",
        "r = df.pivot(index='user_id', columns='item_id', values='rating').values\n",
        "\n",
        "irow, jcol = np.where(~np.isnan(r))\n",
        "\n",
        "cons.print(f\"{len(irow)} entries available\")\n",
        "\n",
        "idx = np.random.choice(np.arange(100_000), 1000, replace=False)\n",
        "test_irow = irow[idx]\n",
        "test_jcol = jcol[idx]\n",
        "\n",
        "r_copy = r.copy()\n",
        "\n",
        "for i in test_irow:\n",
        "    for j in test_jcol:\n",
        "        r_copy[i][j] = np.nan\n",
        "\n",
        "user = UserBased(beta=3, idf=True)\n",
        "\n",
        "sim = user.fit(r_copy)\n",
        "\n",
        "err = []\n",
        "for u, j in zip(test_irow, test_jcol):\n",
        "    y_pred = user.predict1(r_copy, u, j)\n",
        "    y = r[u, j]\n",
        "\n",
        "    err.append((y_pred - y) ** 2)\n",
        "\n",
        "cons.print(f\"RMSE: {np.sqrt(np.nanmean(np.array(err)))}\")"
      ],
      "metadata": {
        "id": "5LKqeeWjv5fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Descent\n",
        "\n",
        "from random import random\n",
        "\n",
        "beta_user = []\n",
        "beta_item = []\n",
        "# creating beta vectors for users and items with random numbers btw 0 and 1\n",
        "for _ in range(r_copy.shape[0]):\n",
        "  beta_user.append(random())\n",
        "for _ in range(r_copy.shape[1]):\n",
        "  beta_item.append(random())\n",
        "# selecting the non-empty elements of r_copy\n",
        "irow_copy, jcol_copy = np.where(~np.isnan(r_copy))\n",
        "\n",
        "alpha = 0.01\n",
        "for i in range(50):\n",
        "  y_error_gd = 0\n",
        "  for u,j in zip(irow_copy, jcol_copy):\n",
        "    g_b = -(r_copy[u,j] - beta_user[u] - beta_item[j]).sum()\n",
        "    y_error_gd += ((r_copy[u,j] - beta_user[u] - beta_item[j])**2)\n",
        "\n",
        "  print(f\"({i}) Gradient: [ {g_b} ], Error: [ {y_error_gd} ]\")\n",
        "\n",
        "  beta_user[u] = beta_user[u] - alpha * g_b\n",
        "  beta_item[j] = beta_item[j] - alpha * g_b"
      ],
      "metadata": {
        "id": "Qm20-vZ7z28S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reguralization\n",
        "\n",
        "from random import random\n",
        "\n",
        "beta_user = []\n",
        "beta_item = []\n",
        "\n",
        "for _ in range(r_copy.shape[0]):\n",
        "  beta_user.append(random())\n",
        "for _ in range(r_copy.shape[1]):\n",
        "  beta_item.append(random())\n",
        "\n",
        "irow_copy, jcol_copy = np.where(~np.isnan(r_copy))\n",
        "\n",
        "lam = random()\n",
        "alpha = 0.01\n",
        "for i in range(10):\n",
        "  y_error_reg = 0\n",
        "  for u,j in zip(irow_copy, jcol_copy):\n",
        "    g_b_user = -(r_copy[u,j] - beta_user[u] - beta_item[j]).sum() - beta_user[u]*lam\n",
        "    g_b_item = -(r_copy[u,j] - beta_user[u] - beta_item[j]).sum() - beta_item[j]*lam\n",
        "    y_error_reg += ((r_copy[u,j] - beta_user[u] - beta_item[j])**2)\n",
        "\n",
        "  print(f\"({i}) Gradient: [ {g_b_user} , {g_b_item} ], Error: [ {y_error_reg} ]\")\n",
        "\n",
        "  beta_user[u] = beta_user[u] - alpha * g_b_user\n",
        "  beta_item[j] = beta_item[j] - alpha * g_b_item"
      ],
      "metadata": {
        "id": "JblXHashGJBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimization of Lambda\n",
        "\n",
        "from random import random\n",
        "\n",
        "lam = random()*5\n",
        "alpha = 0.01\n",
        "for i in range(10):\n",
        "  error_lam = 0\n",
        "  for u,j in zip(test_irow, test_jcol):\n",
        "    g_lam = (beta_user[u]**2 + beta_item[j]**2)/2\n",
        "    error_lam += ((r[u,j] - beta_user[u] - beta_item[j])**2)\n",
        "\n",
        "  print(f\"({i}) Gradient: [ {g_lam} ], Error: [ {error_lam} ]\")\n",
        "\n",
        "  lam = lam - alpha * g_lam\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Lambda sabit olduğu için gradient descent ile optimize edemedim (convex lambda fonksiyonunu bulamadım). \n",
        "Aklıma gelen lambdaya for loop ile 0 ve 5 arasında 0.5 artarak giden değerler vererek en iyi sonuç veren lambdayı bulmak.\n",
        "Fakat manuel bir çözüm olduğu için pek hoşuma gitmedi.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "XbbYzX9wQrA9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
